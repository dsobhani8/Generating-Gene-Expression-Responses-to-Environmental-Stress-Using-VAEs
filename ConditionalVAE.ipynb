{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dsobhani8/Generating-Gene-Expression-Responses-to-Environmental-Stress-Using-VAEs.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spFHLcGMSbRU",
        "outputId": "c5295b21-e4ac-4634-c4fb-f39462ce6a91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generating-Gene-Expression-Responses-to-Environmental-Stress-Using-VAEs'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 20 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 15.50 MiB | 6.79 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BNJBZgaBP1K_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer, LabelEncoder\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_metadata = pd.read_csv('/content/Generating-Gene-Expression-Responses-to-Environmental-Stress-Using-VAEs/data/rice_sra_with_run_accessions.tsv', sep='\\t')\n",
        "df_metadata['run_accessions'] = df_metadata['run_accessions'].apply(lambda x: x.split(',')[0])"
      ],
      "metadata": {
        "id": "q6gn8_8PZ47L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/Generating-Gene-Expression-Responses-to-Environmental-Stress-Using-VAEs/data/combined_counts_matrix.txt.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    with zip_ref.open('combined_counts_matrix.txt') as file:\n",
        "        df = pd.read_csv(file, sep='\\t')\n"
      ],
      "metadata": {
        "id": "yLlN4qNcQhbO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set 'Geneid' as the index to exclude it during transformation (assumed to be gene IDs)\n",
        "df.set_index('Geneid', inplace=True)\n",
        "# Transpose the DataFrame so that 'Accession' (samples) become rows and 'Geneid' (genes) become columns\n",
        "df = df.transpose()"
      ],
      "metadata": {
        "id": "zT3fsEmFQRkk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace=True)\n",
        "df.rename(columns={'index': 'Accession'}, inplace=True)"
      ],
      "metadata": {
        "id": "kLNXUjQwRjCU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_numeric = df.drop(columns=['Accession']).apply(pd.to_numeric, errors='coerce')\n",
        "df_log = np.log1p(df_numeric)\n",
        "scaler = StandardScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df_log), columns=df_log.columns)\n",
        "df_scaled.insert(0, 'Accession', df['Accession'])\n",
        "X = df_scaled.drop(columns=['Accession']).values  # Only the gene expression values\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "m9_AqEfJRk5z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAEDataLoader:\n",
        "    def __init__(self, X, metadata_df=None, batch_size=16, test_size=0.2):\n",
        "        self.batch_size = batch_size\n",
        "        self.test_size = test_size\n",
        "\n",
        "        # Prepare the data and split into train and test sets\n",
        "        if metadata_df is not None:\n",
        "            dataset, metadata_encoded, _ = prepare_data(X, metadata_df)\n",
        "            self.condition_dim = metadata_encoded.shape[1]\n",
        "        else:\n",
        "            dataset, _, _ = prepare_data(X)\n",
        "            self.condition_dim = None\n",
        "\n",
        "        train_data, test_data = train_test_split(dataset, test_size=self.test_size)\n",
        "\n",
        "        # Create train and test DataLoaders\n",
        "        self.train_loader = DataLoader(train_data, batch_size=self.batch_size, shuffle=True)\n",
        "        self.test_loader = DataLoader(test_data, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def get_loaders(self):\n",
        "        return self.train_loader, self.test_loader\n",
        "\n",
        "    def get_condition_dim(self):\n",
        "        return self.condition_dim\n",
        "\n",
        "\n",
        "class FlexibleVAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=10, hidden_dim=128, condition_dim=None):\n",
        "        super(FlexibleVAE, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.condition_dim = condition_dim\n",
        "        self.is_conditional = condition_dim is not None\n",
        "\n",
        "        # Encoder\n",
        "        encoder_input_dim = input_dim + (condition_dim if self.is_conditional else 0)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(encoder_input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        self.fc_mean = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_input_dim = latent_dim + (condition_dim if self.is_conditional else 0)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(decoder_input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def encode(self, x, c=None):\n",
        "        if self.is_conditional and c is not None:\n",
        "            x = torch.cat([x, c], dim=1)\n",
        "        h = self.encoder(x)\n",
        "        return self.fc_mean(h), self.fc_logvar(h)\n",
        "\n",
        "    def decode(self, z, c=None):\n",
        "        if self.is_conditional and c is not None:\n",
        "            z = torch.cat([z, c], dim=1)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * torch.clamp(logvar, min=-10, max=10))\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x, c=None):\n",
        "        mu, logvar = self.encode(x, c)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z, c), mu, logvar\n",
        "\n",
        "def create_metadata_encodings(df):\n",
        "    \"\"\"Create simple one-hot encodings for each unique experimental factor\"\"\"\n",
        "    processed_factors = df['experiment_attribute'].apply(process_experimental_factors)\n",
        "\n",
        "    # Just use MultiLabelBinarizer directly on processed factors\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    factor_encodings = pd.DataFrame(\n",
        "        mlb.fit_transform(processed_factors),\n",
        "        columns=mlb.classes_,\n",
        "        index=df.index\n",
        "    )\n",
        "    print(f\"\\nMetadata encoding shape: {factor_encodings.shape}\")\n",
        "    print(\"\\nFirst few rows of encoded metadata:\")\n",
        "    print(factor_encodings.head())\n",
        "    print(\"\\nUnique factors:\")\n",
        "    print(factor_encodings.columns.tolist())\n",
        "\n",
        "\n",
        "    return factor_encodings, {'all_factors': factor_encodings}  # Keep dict return format for compatibility\n",
        "\n",
        "def process_experimental_factors(experiment_attribute):\n",
        "    \"\"\"Extract experimental factors as single strings\"\"\"\n",
        "    if pd.isna(experiment_attribute):\n",
        "        return []\n",
        "\n",
        "    factors = experiment_attribute.split('||')\n",
        "    processed_factors = []\n",
        "\n",
        "    for factor in factors:\n",
        "        factor = factor.strip()\n",
        "        if factor:  # Keep any non-empty factor\n",
        "            processed_factors.append(factor)\n",
        "\n",
        "    return processed_factors\n",
        "\n",
        "\n",
        "def prepare_data(X, metadata_df=None):\n",
        "    \"\"\"Prepare data for VAE training (conditional or non-conditional)\"\"\"\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "    if metadata_df is not None:\n",
        "        metadata_encoded, encoding_dict = create_metadata_encodings(metadata_df)\n",
        "        condition_tensor = torch.tensor(metadata_encoded.values, dtype=torch.float32)\n",
        "        dataset = TensorDataset(X_tensor, condition_tensor)\n",
        "        return dataset, metadata_encoded, encoding_dict\n",
        "    else:\n",
        "        dataset = TensorDataset(X_tensor)\n",
        "        return dataset, None, None\n",
        "\n",
        "def vae_loss(recon_x, x, mu, logvar, beta=1.0):\n",
        "    \"\"\"Compute VAE loss\"\"\"\n",
        "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + beta * kl_loss\n",
        "\n",
        "def train_vae(model, data_loader, num_epochs=10, device=\"cuda\"):\n",
        "    \"\"\"Train VAE (handles both conditional and non-conditional)\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in data_loader:\n",
        "            if model.is_conditional:\n",
        "                x, c = batch\n",
        "                c = c.to(device, torch.float32)\n",
        "            else:\n",
        "                x = batch[0]\n",
        "                c = None\n",
        "\n",
        "            x = x.to(device, torch.float32)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            recon_x, mu, logvar = model(x, c)\n",
        "            loss = vae_loss(recon_x, x, mu, logvar)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def run_vae_training(df_scaled, df_metadata=None, batch_size=16, num_epochs=10, latent_dim=10):\n",
        "    \"\"\"Run VAE training pipeline with optional conditioning\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare features and dataset\n",
        "    if df_metadata is not None:\n",
        "        # Merge data for conditional VAE\n",
        "        merged_df = df_scaled.merge(\n",
        "            df_metadata,\n",
        "            left_on='Accession',\n",
        "            right_on='run_accessions',\n",
        "            how='inner'\n",
        "        )\n",
        "\n",
        "        gene_cols = [col for col in df_scaled.columns if col != 'Accession']\n",
        "        X = merged_df[gene_cols].values\n",
        "        metadata_df = merged_df[['experiment_attribute']]\n",
        "    else:\n",
        "        X = df_scaled.drop('Accession', axis=1).values\n",
        "        metadata_df = None\n",
        "\n",
        "    # Initialize data loader class\n",
        "    data_loader_class = VAEDataLoader(X, metadata_df, batch_size=batch_size)\n",
        "    train_loader, test_loader = data_loader_class.get_loaders()\n",
        "    condition_dim = data_loader_class.get_condition_dim()\n",
        "\n",
        "    # Initialize the model\n",
        "    model = FlexibleVAE(\n",
        "        input_dim=X.shape[1],\n",
        "        latent_dim=latent_dim,\n",
        "        condition_dim=condition_dim\n",
        "    ).to(device)\n",
        "\n",
        "    # Train the model\n",
        "    train_vae(model, train_loader, num_epochs=num_epochs, device=device)\n",
        "\n",
        "    return model, train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "wFnZuOl-lwPN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(model, data_loader, device=\"cuda\"):\n",
        "    \"\"\"Calculate the Mean Squared Error (MSE) of the VAE reconstructions.\"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    mse_values = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for batch in data_loader:\n",
        "            # Unpack batch data\n",
        "            if model.is_conditional:\n",
        "                x, c = batch\n",
        "                c = c.to(device, torch.float32)\n",
        "            else:\n",
        "                x = batch[0]\n",
        "                c = None\n",
        "\n",
        "            x = x.to(device, torch.float32)\n",
        "\n",
        "            # Obtain reconstruction\n",
        "            recon_x, _, _ = model(x, c)\n",
        "\n",
        "            # Calculate MSE for the current batch and store it\n",
        "            batch_mse = mean_squared_error(x.cpu().numpy(), recon_x.cpu().numpy())\n",
        "            mse_values.append(batch_mse)\n",
        "\n",
        "    # Average MSE across all batches\n",
        "    avg_mse = sum(mse_values) / len(mse_values)\n",
        "    print(f\"Average MSE: {avg_mse:.4f}\")\n",
        "    return avg_mse"
      ],
      "metadata": {
        "id": "c5QouBMKobtQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_vae(model, test_loader, device=\"cuda\"):\n",
        "    \"\"\"Evaluate VAE performance on test data using MSE.\"\"\"\n",
        "    average_mse = calculate_mse(model, test_loader, device=device)\n",
        "    print(f\"Test MSE: {average_mse:.4f}\")\n",
        "    return average_mse\n",
        "\n",
        "model, train_loader, test_loader = run_vae_training(df_scaled,num_epochs=25)\n",
        "test_mse = evaluate_vae(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_iIJCfQoJvy",
        "outputId": "4734aa9b-23c8-4316-c3cd-ce4b0ab3e158"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Average Loss: 596152.9282\n",
            "Epoch [2/25], Average Loss: 447480.9924\n",
            "Epoch [3/25], Average Loss: 414536.3833\n",
            "Epoch [4/25], Average Loss: 416190.1109\n",
            "Epoch [5/25], Average Loss: 410037.6110\n",
            "Epoch [6/25], Average Loss: 411774.3387\n",
            "Epoch [7/25], Average Loss: 404694.9171\n",
            "Epoch [8/25], Average Loss: 397345.3033\n",
            "Epoch [9/25], Average Loss: 389804.8549\n",
            "Epoch [10/25], Average Loss: 383074.8223\n",
            "Epoch [11/25], Average Loss: 378170.7313\n",
            "Epoch [12/25], Average Loss: 367436.2211\n",
            "Epoch [13/25], Average Loss: 361295.7977\n",
            "Epoch [14/25], Average Loss: 356891.4823\n",
            "Epoch [15/25], Average Loss: 350172.8084\n",
            "Epoch [16/25], Average Loss: 351528.9884\n",
            "Epoch [17/25], Average Loss: 345211.3285\n",
            "Epoch [18/25], Average Loss: 340561.5092\n",
            "Epoch [19/25], Average Loss: 337946.4662\n",
            "Epoch [20/25], Average Loss: 334145.5120\n",
            "Epoch [21/25], Average Loss: 334369.1574\n",
            "Epoch [22/25], Average Loss: 329238.6068\n",
            "Epoch [23/25], Average Loss: 328324.2372\n",
            "Epoch [24/25], Average Loss: 322469.1881\n",
            "Epoch [25/25], Average Loss: 321225.7942\n",
            "Average MSE: 0.4650\n",
            "Test MSE: 0.4650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model2, train_loader, test_loader = run_vae_training(df_scaled,df_metadata=df_metadata,num_epochs=25)\n",
        "# test_mse = evaluate_vae(model2, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "collapsed": true,
        "id": "rGVq2F9flwZA",
        "outputId": "3457eebf-6ffa-41f6-b506-c4744ebe8c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-336dafabb23e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_vae_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-eb23fc772cd6>\u001b[0m in \u001b[0;36mrun_vae_training\u001b[0;34m(df_scaled, df_metadata, batch_size, num_epochs, latent_dim)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-eb23fc772cd6>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m(model, data_loader, num_epochs, device)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_conditional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zxpOFGTgRAmG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}